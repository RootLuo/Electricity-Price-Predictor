{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline\n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PJM Has a REST API\n",
    "\n",
    "PJM has documentation for a REST API available at http://www.pjm.com/~/media/etools/data-miner/user-guide.ashx\n",
    "\n",
    "We'll use the API to get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These are all the nodes we're interested in so far.\n",
    "nodeList = [\n",
    "    5021673,\n",
    "    32417525,\n",
    "    32417527,\n",
    "    32417545,\n",
    "    32417547,\n",
    "    32417599,\n",
    "    32417601,\n",
    "    32417629,\n",
    "    32417631,\n",
    "    32417633,\n",
    "    32417635\n",
    "]\n",
    "#This is the base URL for the PJM REST API\n",
    "url = 'https://dataminer.pjm.com/dataminer/rest/public/api/markets/realtime/lmp/daily'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDateTime(utchour):\n",
    "    #split datetime into date and time components\n",
    "    datetime_parts = utchour.split('T', 1)\n",
    "    parts = dict(date = datetime_parts[0], time = datetime_parts[1].rstrip('Z'))\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#Using code adapted from http://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python\n",
    "def daterange(start, end):\n",
    "    for n in range(int((end - start).days)):\n",
    "        yield start + timedelta(n)\n",
    "        \n",
    "def formatDate(aDate):\n",
    "    return aDate.strftime('%Y-%m-%d')\n",
    "\n",
    "def adjustTime(parts):\n",
    "    dtstring = parts['date'] + ' ' + parts['time']\n",
    "    dtformat = '%Y-%m-%d %H:%M:%S'\n",
    "    adjusted = datetime.datetime.strptime(dtstring, dtformat) - timedelta(hours = 4)\n",
    "    return adjusted\n",
    "\n",
    "def getHour(adjustedDatetime):\n",
    "    t = adjustedDatetime.time()\n",
    "    tstring = t.strftime('%H:%M:%S')\n",
    "    tparts = tstring.split(':', 2)\n",
    "    return tparts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HERE IS THE BIG KAHUNA\n",
    "#This will take a long-ass time to run (25 mins), because we have to loop over every day in the years 2008 - 2012\n",
    "\n",
    "#set up our json POST data\n",
    "params_list = [\n",
    "    dict(startDate = formatDate(date(2008, 1, 1)), endDate = formatDate(date(2008, 12, 31)), pnodeList = nodeList),\n",
    "    dict(startDate = formatDate(date(2009, 1, 1)), endDate = formatDate(date(2009, 12, 31)), pnodeList = nodeList),\n",
    "    dict(startDate = formatDate(date(2010, 1, 1)), endDate = formatDate(date(2010, 12, 31)), pnodeList = nodeList),\n",
    "    dict(startDate = formatDate(date(2011, 1, 1)), endDate = formatDate(date(2011, 12, 31)), pnodeList = nodeList),\n",
    "    dict(startDate = formatDate(date(2012, 1, 1)), endDate = formatDate(date(2012, 12, 31)), pnodeList = nodeList)\n",
    "]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for i in range(0, len(params_list)):\n",
    "    \n",
    "    #make the API call\n",
    "    r = requests.post(url, json = params_list[i])\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        results_dict[i] = r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "        \n",
    "    #be nice to the API, wait 2 seconds\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recordsList = []\n",
    "for result in results_dict.values():\n",
    "    \n",
    "    #make a new row for each individual price\n",
    "    for record in result:\n",
    "        #we are only interested in Total LMP per Sam's email\n",
    "        if record['priceType'] == 'TotalLMP':\n",
    "            data = {}\n",
    "            data['pnodeId'] = record['pnodeId']\n",
    "            published = splitDateTime(record['publishDate'])\n",
    "            data['publishDate'] = published['date']\n",
    "            for p in record['prices']:\n",
    "                utcparts = splitDateTime(p['utchour'])\n",
    "                hour = getHour(adjustTime(utcparts))\n",
    "                if hour == '00':\n",
    "                    hour = '24'\n",
    "                key = 'price_' + hour\n",
    "                data[key] = p['price']\n",
    "            recordsList.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pnodeId': 32417601,\n",
       "  'price_01': 44.68,\n",
       "  'price_02': 28.91,\n",
       "  'price_03': 2.48,\n",
       "  'price_04': 14.23,\n",
       "  'price_05': 13.66,\n",
       "  'price_06': 21.55,\n",
       "  'price_07': 21.44,\n",
       "  'price_08': 21.79,\n",
       "  'price_09': 22.94,\n",
       "  'price_10': 24.15,\n",
       "  'price_11': 23.06,\n",
       "  'price_12': 26.53,\n",
       "  'price_13': 29.16,\n",
       "  'price_14': 26.03,\n",
       "  'price_15': 27.36,\n",
       "  'price_16': 26.25,\n",
       "  'price_17': 26.41,\n",
       "  'price_18': 26.57,\n",
       "  'price_19': 28.61,\n",
       "  'price_20': 65.92,\n",
       "  'price_21': 72.45,\n",
       "  'price_22': 75.68,\n",
       "  'price_23': 76.83,\n",
       "  'price_24': 46.26,\n",
       "  'publishDate': u'2008-01-01'},\n",
       " {'pnodeId': 32417601,\n",
       "  'price_01': 98.31,\n",
       "  'price_02': 65.93,\n",
       "  'price_03': 26.73,\n",
       "  'price_04': 31.48,\n",
       "  'price_05': 30.66,\n",
       "  'price_06': 27.92,\n",
       "  'price_07': 35.38,\n",
       "  'price_08': 31.03,\n",
       "  'price_09': 41.06,\n",
       "  'price_10': 90.86,\n",
       "  'price_11': 108.73,\n",
       "  'price_12': 138.98,\n",
       "  'price_13': 102.04,\n",
       "  'price_14': 89.39,\n",
       "  'price_15': 80.84,\n",
       "  'price_16': 92.72,\n",
       "  'price_17': 52.36,\n",
       "  'price_18': 28.21,\n",
       "  'price_19': 52.29,\n",
       "  'price_20': 85.35,\n",
       "  'price_21': 129.36,\n",
       "  'price_22': 153.18,\n",
       "  'price_23': 161.66,\n",
       "  'price_24': 102.92,\n",
       "  'publishDate': u'2008-01-02'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see what we have. It's probably obscenely huge.\n",
    "#print rawdf.shape\n",
    "#results_dict[0][0:3]\n",
    "print len(recordsList)\n",
    "recordsList[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdf.to_csv('rawdf_pjm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
